{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad77192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import spikeinterface.full as si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a967c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HDF5_PLUGIN_PATH'] = '/home/phornauer/MaxLab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d5c7ed",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b98f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/net/bs-filesvr02/export/group/hierlemann/recordings/Mea1k/phornauer/GM/221104/M05180/Network/000041'\n",
    "file_name = \"data.raw.h5\"\n",
    "rec_path = os.path.join(input_path, file_name)\n",
    "save_path = '/net/bs-filesvr02/export/group/hierlemann/intermediate_data/Mea1k/phornauer/si2/KS25/221104/M05180/'\n",
    "assert (os.path.exists(rec_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "949b145b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'detect_threshold': 6, 'projection_threshold': [10, 4], 'preclust_threshold': 8, 'car': True, 'minFR': 0.1, 'minfr_goodchannels': 0.1, 'nblocks': 5, 'sig': 20, 'freq_min': 150, 'sigmaMask': 30, 'nPCs': 3, 'ntbuff': 64, 'nfilt_factor': 4, 'NT': None, 'do_correction': True, 'wave_length': 61, 'keep_good_only': False, 'n_jobs': -1, 'total_memory': None, 'chunk_size': None, 'chunk_memory': None, 'chunk_duration': '1s', 'progress_bar': True}\n"
     ]
    }
   ],
   "source": [
    "sorter_params = si.get_default_sorter_params(si.Kilosort2_5Sorter)\n",
    "sorter_params['n_jobs'] = -1\n",
    "print(sorter_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9994c527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting KILOSORT2_5_PATH environment variable for subprocess calls to: /home/phornauer/Git/Kilosort\n"
     ]
    }
   ],
   "source": [
    "sorter = 'kilosort2_5'\n",
    "si.Kilosort2_5Sorter.set_kilosort2_5_path('/home/phornauer/Git/Kilosort')\n",
    "output_folder = Path(os.path.join(save_path, 'sorted'))\n",
    "cache_folder = Path(os.path.join(save_path, 'cache'))\n",
    "figures_folder = Path(os.path.join(save_path, 'figures'))\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "cache_folder.mkdir(parents=True, exist_ok=True)\n",
    "figures_folder.mkdir(parents=True, exist_ok=True)\n",
    "tmp_folder = cache_folder / 'tmp' / sorter\n",
    "tmp_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ab2d193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION: 600.06 s -- NUM. CHANNELS: 1020\n"
     ]
    }
   ],
   "source": [
    "rec = si.MaxwellRecordingExtractor(rec_path,stream_id='well000')\n",
    "print(f\"DURATION: {rec.get_num_frames() / rec.get_sampling_frequency()} s -- \"\n",
    "      f\"NUM. CHANNELS: {rec.get_num_channels()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a22d5094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_binary_recording with n_jobs = 4 and chunk_size = 10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e0ebc2b9b446cc85ed2f49a18123db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording:   0%|          | 0/601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "\n",
      "Maxwell file format is based on HDF5.\n",
      "The internal compression requires a custom plugin!!!\n",
      "This is a big pain for the end user.\n",
      "You, as a end user, should ask Maxwell company to change this.\n",
      "Please visit this page and install the missing decompression libraries:\n",
      "https://share.mxwbio.com/d/4742248b2e674a85be97/\n",
      "Then, link the decompression library by setting the `HDF5_PLUGIN_PATH` to your\n",
      "installation location, e.g. via\n",
      "os.environ['HDF5_PLUGIN_PATH'] = '/path/to/cutum/hdf5/plugin/'\n",
      "\n",
      "Alternatively, you can use the auto_install_maxwell_hdf5_compression_plugin() below\n",
      "function that do it automagically.\n",
      "Maxwell file format is based on HDF5.\n",
      "The internal compression requires a custom plugin!!!\n",
      "This is a big pain for the end user.\n",
      "You, as a end user, should ask Maxwell company to change this.\n",
      "Please visit this page and install the missing decompression libraries:\n",
      "https://share.mxwbio.com/d/4742248b2e674a85be97/\n",
      "Then, link the decompression library by setting the `HDF5_PLUGIN_PATH` to your\n",
      "installation location, e.g. via\n",
      "os.environ['HDF5_PLUGIN_PATH'] = '/path/to/cutum/hdf5/plugin/'\n",
      "\n",
      "Alternatively, you can use the auto_install_maxwell_hdf5_compression_plugin() below\n",
      "function that do it automagically.\n",
      "**********\n",
      "\n",
      "********************\n",
      "\n",
      "\n",
      "**********Maxwell file format is based on HDF5.\n",
      "The internal compression requires a custom plugin!!!\n",
      "This is a big pain for the end user.\n",
      "You, as a end user, should ask Maxwell company to change this.\n",
      "Please visit this page and install the missing decompression libraries:\n",
      "https://share.mxwbio.com/d/4742248b2e674a85be97/\n",
      "Then, link the decompression library by setting the `HDF5_PLUGIN_PATH` to your\n",
      "installation location, e.g. via\n",
      "os.environ['HDF5_PLUGIN_PATH'] = '/path/to/cutum/hdf5/plugin/'\n",
      "\n",
      "Alternatively, you can use the auto_install_maxwell_hdf5_compression_plugin() below\n",
      "function that do it automagically.\n",
      "\n",
      "\n",
      "Maxwell file format is based on HDF5.\n",
      "The internal compression requires a custom plugin!!!\n",
      "This is a big pain for the end user.\n",
      "You, as a end user, should ask Maxwell company to change this.\n",
      "Please visit this page and install the missing decompression libraries:\n",
      "https://share.mxwbio.com/d/4742248b2e674a85be97/\n",
      "Then, link the decompression library by setting the `HDF5_PLUGIN_PATH` to your\n",
      "installation location, e.g. via\n",
      "os.environ['HDF5_PLUGIN_PATH'] = '/path/to/cutum/hdf5/plugin/'\n",
      "\n",
      "Alternatively, you can use the auto_install_maxwell_hdf5_compression_plugin() below\n",
      "function that do it automagically.\n",
      "**********\n",
      "\n",
      "******************************\n",
      "\n",
      "\n",
      "Maxwell file format is based on HDF5.\n",
      "The internal compression requires a custom plugin!!!\n",
      "This is a big pain for the end user.\n",
      "You, as a end user, should ask Maxwell company to change this.\n",
      "Please visit this page and install the missing decompression libraries:\n",
      "https://share.mxwbio.com/d/4742248b2e674a85be97/\n",
      "Then, link the decompression library by setting the `HDF5_PLUGIN_PATH` to your\n",
      "installation location, e.g. via\n",
      "os.environ['HDF5_PLUGIN_PATH'] = '/path/to/cutum/hdf5/plugin/'\n",
      "\n",
      "Alternatively, you can use the auto_install_maxwell_hdf5_compression_plugin() below\n",
      "function that do it automagically.\n",
      "\n",
      "**********Maxwell file format is based on HDF5.\n",
      "The internal compression requires a custom plugin!!!\n",
      "This is a big pain for the end user.\n",
      "You, as a end user, should ask Maxwell company to change this.\n",
      "Please visit this page and install the missing decompression libraries:\n",
      "https://share.mxwbio.com/d/4742248b2e674a85be97/\n",
      "Then, link the decompression library by setting the `HDF5_PLUGIN_PATH` to your\n",
      "installation location, e.g. via\n",
      "os.environ['HDF5_PLUGIN_PATH'] = '/path/to/cutum/hdf5/plugin/'\n",
      "\n",
      "Alternatively, you can use the auto_install_maxwell_hdf5_compression_plugin() below\n",
      "function that do it automagically.\n",
      "\n",
      "********************\n",
      "\n",
      "Maxwell file format is based on HDF5.\n",
      "The internal compression requires a custom plugin!!!\n",
      "This is a big pain for the end user.\n",
      "You, as a end user, should ask Maxwell company to change this.\n",
      "Please visit this page and install the missing decompression libraries:\n",
      "https://share.mxwbio.com/d/4742248b2e674a85be97/\n",
      "Then, link the decompression library by setting the `HDF5_PLUGIN_PATH` to your\n",
      "installation location, e.g. via\n",
      "os.environ['HDF5_PLUGIN_PATH'] = '/path/to/cutum/hdf5/plugin/'\n",
      "\n",
      "Alternatively, you can use the auto_install_maxwell_hdf5_compression_plugin() below\n",
      "function that do it automagically.\n",
      "\n",
      "**********\n",
      "**********Maxwell file format is based on HDF5.\n",
      "The internal compression requires a custom plugin!!!\n",
      "This is a big pain for the end user.\n",
      "You, as a end user, should ask Maxwell company to change this.\n",
      "Please visit this page and install the missing decompression libraries:\n",
      "https://share.mxwbio.com/d/4742248b2e674a85be97/\n",
      "Then, link the decompression library by setting the `HDF5_PLUGIN_PATH` to your\n",
      "installation location, e.g. via\n",
      "os.environ['HDF5_PLUGIN_PATH'] = '/path/to/cutum/hdf5/plugin/'\n",
      "\n",
      "Alternatively, you can use the auto_install_maxwell_hdf5_compression_plugin() below\n",
      "function that do it automagically.\n",
      "\n",
      "\n",
      "\n",
      "********************\n",
      "\n",
      "Maxwell file format is based on HDF5.\n",
      "The internal compression requires a custom plugin!!!\n",
      "This is a big pain for the end user.\n",
      "You, as a end user, should ask Maxwell company to change this.\n",
      "Please visit this page and install the missing decompression libraries:\n",
      "https://share.mxwbio.com/d/4742248b2e674a85be97/\n",
      "Then, link the decompression library by setting the `HDF5_PLUGIN_PATH` to your\n",
      "installation location, e.g. via\n",
      "os.environ['HDF5_PLUGIN_PATH'] = '/path/to/cutum/hdf5/plugin/'\n",
      "\n",
      "Alternatively, you can use the auto_install_maxwell_hdf5_compression_plugin() below\n",
      "function that do it automagically.\n",
      "\n",
      "**********\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't read data (can't open directory: /home/phornauer/miniconda3/envs/si_env/lib/hdf5/plugin)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/phornauer/miniconda3/envs/si_env/lib/python3.9/concurrent/futures/process.py\", line 246, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/home/phornauer/miniconda3/envs/si_env/lib/python3.9/concurrent/futures/process.py\", line 205, in _process_chunk\n    return [fn(*args) for args in chunk]\n  File \"/home/phornauer/miniconda3/envs/si_env/lib/python3.9/concurrent/futures/process.py\", line 205, in <listcomp>\n    return [fn(*args) for args in chunk]\n  File \"/home/phornauer/Git/spikeinterface/spikeinterface/core/job_tools.py\", line 369, in function_wrapper\n    return _func(segment_index, start_frame, end_frame, _worker_ctx)\n  File \"/home/phornauer/Git/spikeinterface/spikeinterface/core/core_tools.py\", line 208, in _write_binary_chunk\n    traces = recording.get_traces(start_frame=start_frame, end_frame=end_frame, segment_index=segment_index,\n  File \"/home/phornauer/Git/spikeinterface/spikeinterface/core/baserecording.py\", line 119, in get_traces\n    traces = rs.get_traces(start_frame=start_frame, end_frame=end_frame, channel_indices=channel_indices)\n  File \"/home/phornauer/Git/spikeinterface/spikeinterface/preprocessing/filter.py\", line 109, in get_traces\n    traces_chunk, left_margin, right_margin = get_chunk_with_margin(self.parent_recording_segment,\n  File \"/home/phornauer/Git/spikeinterface/spikeinterface/core/recording_tools.py\", line 145, in get_chunk_with_margin\n    traces_chunk = rec_segment.get_traces(start_frame - left_margin, end_frame + right_margin, channel_indices)\n  File \"/home/phornauer/Git/spikeinterface/spikeinterface/extractors/neoextractors/neobaseextractor.py\", line 180, in get_traces\n    raw_traces = self.neo_reader.get_analogsignal_chunk(\n  File \"/home/phornauer/miniconda3/envs/si_env/lib/python3.9/site-packages/neo/rawio/baserawio.py\", line 574, in get_analogsignal_chunk\n    raw_chunk = self._get_analogsignal_chunk(\n  File \"/home/phornauer/miniconda3/envs/si_env/lib/python3.9/site-packages/neo/rawio/maxwellrawio.py\", line 208, in _get_analogsignal_chunk\n    raise(e)\n  File \"/home/phornauer/miniconda3/envs/si_env/lib/python3.9/site-packages/neo/rawio/maxwellrawio.py\", line 196, in _get_analogsignal_chunk\n    sigs = sigs[channel_indexes, i_start:i_stop]\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"/home/phornauer/miniconda3/envs/si_env/lib/python3.9/site-packages/h5py/_hl/dataset.py\", line 741, in __getitem__\n    return self._fast_reader.read(args)\n  File \"h5py/_selector.pyx\", line 370, in h5py._selector.Reader.read\nOSError: Can't read data (can't open directory: /home/phornauer/miniconda3/envs/si_env/lib/hdf5/plugin)\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m rec_f \u001b[38;5;241m=\u001b[39m si\u001b[38;5;241m.\u001b[39mhighpass_filter(rec, freq_min\u001b[38;5;241m=\u001b[39msorter_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreq_min\u001b[39m\u001b[38;5;124m'\u001b[39m],dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m rec_cache \u001b[38;5;241m=\u001b[39m \u001b[43mrec_f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecording\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msorter_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_jobs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m stop \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElapsed saving time \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mround(stop \u001b[38;5;241m-\u001b[39m start, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Git/spikeinterface/spikeinterface/core/base.py:613\u001b[0m, in \u001b[0;36mBaseExtractor.save\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m     loaded_extractor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_to_zarr(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 613\u001b[0m     loaded_extractor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_to_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded_extractor\n",
      "File \u001b[0;32m~/Git/spikeinterface/spikeinterface/core/base.py:692\u001b[0m, in \u001b[0;36mBaseExtractor.save_to_folder\u001b[0;34m(self, name, folder, verbose, **save_kwargs)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_metadata_to_folder(folder)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;66;03m# save data (done the subclass)\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msave_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# copy properties/\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_metadata(cached)\n",
      "File \u001b[0;32m~/Git/spikeinterface/spikeinterface/core/baserecording.py:223\u001b[0m, in \u001b[0;36mBaseRecording._save\u001b[0;34m(self, format, **save_kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m [folder \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraces_cached_seg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.raw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_segments())]\n\u001b[1;32m    221\u001b[0m dtype \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dtype()\n\u001b[0;32m--> 223\u001b[0m \u001b[43mwrite_binary_recording\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mjob_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbinaryrecordingextractor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BinaryRecordingExtractor\n\u001b[1;32m    226\u001b[0m binary_rec \u001b[38;5;241m=\u001b[39m BinaryRecordingExtractor(file_paths\u001b[38;5;241m=\u001b[39mfile_paths, sampling_frequency\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sampling_frequency(),\n\u001b[1;32m    227\u001b[0m                                       num_chan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_channels(), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    228\u001b[0m                                       t_starts\u001b[38;5;241m=\u001b[39mt_starts, channel_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_channel_ids(), time_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    229\u001b[0m                                       file_offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, gain_to_uV\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_channel_gains(),\n\u001b[1;32m    230\u001b[0m                                       offset_to_uV\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_channel_offsets())\n",
      "File \u001b[0;32m~/Git/spikeinterface/spikeinterface/core/core_tools.py:278\u001b[0m, in \u001b[0;36mwrite_binary_recording\u001b[0;34m(recording, file_paths, dtype, add_file_extension, verbose, byte_offset, auto_cast_uint, **job_kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m     init_args \u001b[38;5;241m=\u001b[39m (recording\u001b[38;5;241m.\u001b[39mto_dict(), rec_memmaps_dict, dtype, cast_unsigned)\n\u001b[1;32m    276\u001b[0m executor \u001b[38;5;241m=\u001b[39m ChunkRecordingExecutor(recording, func, init_func, init_args, verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    277\u001b[0m                                   job_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrite_binary_recording\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjob_kwargs)\n\u001b[0;32m--> 278\u001b[0m \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Git/spikeinterface/spikeinterface/core/job_tools.py:334\u001b[0m, in \u001b[0;36mChunkRecordingExecutor.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 returns\u001b[38;5;241m.\u001b[39mappend(res)\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m    335\u001b[0m                 \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m returns\n",
      "File \u001b[0;32m~/miniconda3/envs/si_env/lib/python3.9/site-packages/tqdm/notebook.py:259\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/si_env/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/si_env/lib/python3.9/concurrent/futures/process.py:562\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 562\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    563\u001b[0m         element\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m~/miniconda3/envs/si_env/lib/python3.9/concurrent/futures/_base.py:609\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mresult(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/miniconda3/envs/si_env/lib/python3.9/concurrent/futures/_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/miniconda3/envs/si_env/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't read data (can't open directory: /home/phornauer/miniconda3/envs/si_env/lib/hdf5/plugin)"
     ]
    }
   ],
   "source": [
    "rec_f = si.highpass_filter(rec, freq_min=sorter_params['freq_min'],dtype='int16')\n",
    "start = time.time()\n",
    "rec_cache = rec_f.save(folder=cache_folder / \"recording\", n_jobs=sorter_params['n_jobs'], chunk_size=10000,\n",
    "                        progress_bar=True)\n",
    "stop = time.time()\n",
    "print(f'Elapsed saving time {np.round(stop - start, 2)}\\n')\n",
    "print(f\"Filtered recording saved to {cache_folder / 'recording'}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5ff0957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved recording\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This folder is not a cached folder /net/bs-filesvr02/export/group/hierlemann/intermediate_data/Mea1k/phornauer/si2/KS25/221104/M05180/cache/recording",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (cache_folder \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecording\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading saved recording\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     rec_cache \u001b[38;5;241m=\u001b[39m \u001b[43msi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecording\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFILTERING\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Git/spikeinterface/spikeinterface/core/base.py:911\u001b[0m, in \u001b[0;36mload_extractor\u001b[0;34m(file_or_folder_or_dict, base_folder)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BaseExtractor\u001b[38;5;241m.\u001b[39mfrom_dict(file_or_folder_or_dict, base_folder\u001b[38;5;241m=\u001b[39mbase_folder)\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 911\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBaseExtractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_or_folder_or_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Git/spikeinterface/spikeinterface/core/base.py:557\u001b[0m, in \u001b[0;36mBaseExtractor.load\u001b[0;34m(file_path, base_folder)\u001b[0m\n\u001b[1;32m    554\u001b[0m     file \u001b[38;5;241m=\u001b[39m f\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis folder is not a cached folder \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    558\u001b[0m extractor \u001b[38;5;241m=\u001b[39m BaseExtractor\u001b[38;5;241m.\u001b[39mload(file, base_folder\u001b[38;5;241m=\u001b[39mfolder)\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extractor\n",
      "\u001b[0;31mValueError\u001b[0m: This folder is not a cached folder /net/bs-filesvr02/export/group/hierlemann/intermediate_data/Mea1k/phornauer/si2/KS25/221104/M05180/cache/recording"
     ]
    }
   ],
   "source": [
    "### Filter and dumping\n",
    "if (cache_folder / 'recording').is_dir():\n",
    "    print(\"Loading saved recording\")\n",
    "    rec_cache = si.load_extractor(cache_folder / 'recording')\n",
    "else:\n",
    "    print('FILTERING\\n')\n",
    "    rec_f = si.highpass_filter(rec, freq_min=sorter_params['freq_min'],dtype='int16')\n",
    "    start = time.time()\n",
    "    rec_cache = rec_f.save(folder=cache_folder / \"recording\", n_jobs=sorter_params['n_jobs'], chunk_size=10000,\n",
    "                            progress_bar=True)\n",
    "    stop = time.time()\n",
    "    print(f'Elapsed saving time {np.round(stop - start, 2)}\\n')\n",
    "    print(f\"Filtered recording saved to {cache_folder / 'recording'}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04e27cc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rec_cache' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m t_start_sort \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m sorting \u001b[38;5;241m=\u001b[39m si\u001b[38;5;241m.\u001b[39mrun_sorter(sorter, \u001b[43mrec_cache\u001b[49m, output_folder\u001b[38;5;241m=\u001b[39moutput_folder, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      3\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msorter_params)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSpike sorting elapsed time \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_start_sort\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rec_cache' is not defined"
     ]
    }
   ],
   "source": [
    "t_start_sort = time.time()\n",
    "sorting = si.run_sorter(sorter, rec_cache, output_folder=output_folder, verbose=True,\n",
    "                        **sorter_params)\n",
    "print(f\"\\n\\nSpike sorting elapsed time {time.time() - t_start_sort} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54fcac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
